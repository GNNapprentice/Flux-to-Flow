{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b30283-c451-4ec9-aa44-a44275b9bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global parameters for no. of trips in each simulation , time steps between each time and size of dataset \n",
    "\n",
    "num_trips = 100\n",
    "time_step = 2\n",
    "datasize = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c312e7d-0df5-4b0b-aece-3c08e37889c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter your network file\n",
    "\n",
    "network_file = \"reduced.net.xml\"\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_edge_ids(net_file_path):\n",
    "  \"\"\"\n",
    "  Reads a SUMO network file and returns a list of all edge IDs.\n",
    "\n",
    "  Args:\n",
    "    net_file_path: The path to the SUMO network file (.net.xml).\n",
    "\n",
    "  Returns:\n",
    "    A list of strings, where each string is an edge ID.\n",
    "    Returns an empty list if the file is not found or if an error occurs.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    tree = ET.parse(net_file_path)\n",
    "    root = tree.getroot()\n",
    "    edge_ids = [edge.get('id') for edge in root.findall('edge')]\n",
    "    return edge_ids\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {net_file_path}\")\n",
    "    return []\n",
    "  except ET.ParseError:\n",
    "    print(f\"Error: Invalid XML format in {net_file_path}\")\n",
    "    return []\n",
    "  except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    return []\n",
    "\n",
    "\n",
    "# Example usage (replace with your actual file path):\n",
    "edge_list = get_edge_ids(network_file)\n",
    "print(f\"done!\")\n",
    "\n",
    "# if edge_list:\n",
    "#   print(\"Edge IDs in the network:\")\n",
    "#   for edge_id in edge_list:\n",
    "#     print(edge_id)\n",
    "# else:\n",
    "#     print(\"Failed to retrieve edge IDs.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90787509-c707-4b19-8570-3d0739af8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_nodes_from_edges(net_file_path):\n",
    "    \"\"\"\n",
    "    Reads a SUMO network file and returns a list of all nodes from and to.\n",
    "\n",
    "    Args:\n",
    "      net_file_path: The path to the SUMO network file (.net.xml).\n",
    "\n",
    "    Returns:\n",
    "      A list of strings, where each string is a node ID.\n",
    "      Returns an empty list if the file is not found or if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(net_file_path)\n",
    "        root = tree.getroot()\n",
    "        nodes = set()  # Use a set to avoid duplicate nodes\n",
    "        for edge in root.findall('edge'):\n",
    "            from_node = edge.get('from')\n",
    "            to_node = edge.get('to')\n",
    "            if from_node:\n",
    "                nodes.add(from_node)\n",
    "            if to_node:\n",
    "                nodes.add(to_node)\n",
    "        return list(nodes)  # Convert the set back to a list\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {net_file_path}\")\n",
    "        return []\n",
    "    except ET.ParseError:\n",
    "        print(f\"Error: Invalid XML format in {net_file_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "node_list = get_nodes_from_edges(network_file)\n",
    "\n",
    "if node_list:\n",
    "    print(\"Nodes in the network:\")\n",
    "    for node_id in node_list:\n",
    "        print(node_id)\n",
    "else:\n",
    "    print(\"Failed to retrieve nodes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac17ff92-69d6-484c-a98b-534e7b273a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import networkx as nx\n",
    "\n",
    "def create_graph_from_net_file(net_file_path):\n",
    "    \"\"\"\n",
    "    Creates a graph from a SUMO network file.\n",
    "\n",
    "    Args:\n",
    "        net_file_path: The path to the SUMO network file (.net.xml).\n",
    "\n",
    "    Returns:\n",
    "        A NetworkX graph object representing the network, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(net_file_path)\n",
    "        root = tree.getroot()\n",
    "        graph = nx.DiGraph()  # Use a directed graph for SUMO networks\n",
    "\n",
    "        for edge in root.findall('edge'):\n",
    "            from_node = edge.get('from')\n",
    "            to_node = edge.get('to')\n",
    "            edge_id = edge.get('id')\n",
    "            if from_node and to_node and edge_id:\n",
    "                graph.add_edge(from_node, to_node, id=edge_id) # Store edge ID as attribute\n",
    "        return graph\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {net_file_path}\")\n",
    "        return None\n",
    "    except ET.ParseError:\n",
    "        print(f\"Error: Invalid XML format in {net_file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "network_graph = create_graph_from_net_file(network_file)\n",
    "\n",
    "if network_graph:\n",
    "    print(\"Graph created successfully!\")\n",
    "    # Now you can work with the network_graph object\n",
    "    # For example, print some information about the graph:\n",
    "    print(f\"Number of nodes: {network_graph.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {network_graph.number_of_edges()}\")\n",
    "\n",
    "    # Print edges with their IDs (attributes)\n",
    "    for u, v, data in network_graph.edges(data=True):\n",
    "      print(f\"Edge from {u} to {v} with ID: {data['id']}\")\n",
    "else:\n",
    "    print(\"Failed to create the graph.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0717593-cfca-431b-b589-beeb6656227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: create a dual graph of the above\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import networkx as nx\n",
    "\n",
    "def create_dual_graph(net_file_path):\n",
    "    \"\"\"\n",
    "    Creates a dual graph from a SUMO network file.\n",
    "\n",
    "    Args:\n",
    "        net_file_path: The path to the SUMO network file (.net.xml).\n",
    "\n",
    "    Returns:\n",
    "        A NetworkX graph object representing the dual graph, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(net_file_path)\n",
    "        root = tree.getroot()\n",
    "        dual_graph = nx.Graph()  # Use an undirected graph for the dual\n",
    "\n",
    "        # Assuming edges in the SUMO network represent connections between nodes\n",
    "        for edge in root.findall('edge'):\n",
    "            from_node = edge.get('from')\n",
    "            to_node = edge.get('to')\n",
    "            edge_id = edge.get('id')  # Use edge ID for dual graph nodes\n",
    "\n",
    "            if from_node and to_node and edge_id:\n",
    "                dual_graph.add_node(edge_id, from_node=from_node, to_node=to_node)\n",
    "\n",
    "        # Connect nodes in the dual graph based on shared nodes in the original graph\n",
    "        for edge1 in root.findall('edge'):\n",
    "          for edge2 in root.findall('edge'):\n",
    "            edge1_id = edge1.get('id')\n",
    "            edge2_id = edge2.get('id')\n",
    "            if edge1_id != edge2_id:\n",
    "                if edge1.get('to') == edge2.get('from'):\n",
    "                    dual_graph.add_edge(edge1_id, edge2_id)\n",
    "\n",
    "        return dual_graph\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {net_file_path}\")\n",
    "        return None\n",
    "    except ET.ParseError:\n",
    "        print(f\"Error: Invalid XML format in {net_file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "dual_graph = create_dual_graph(network_file)\n",
    "\n",
    "\n",
    "if dual_graph:\n",
    "  print(\"Dual graph created successfully!\")\n",
    "  print(f\"Number of nodes in dual graph: {dual_graph.number_of_nodes()}\")\n",
    "  print(f\"Number of edges in dual graph: {dual_graph.number_of_edges()}\")\n",
    "  for u, v in dual_graph.edges:\n",
    "    print(f\"Edge in dual graph: {u} - {v}\")\n",
    "else:\n",
    "    print(\"Failed to create the dual graph.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef925-594c-4af4-ae9a-d0514fcbe6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_adjacency_matrix(graph):\n",
    "    \"\"\"Creates an adjacency matrix for a given graph.\"\"\"\n",
    "    nodes = sorted(graph.nodes())\n",
    "    n = len(nodes)\n",
    "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
    "    for u, v in graph.edges():\n",
    "        u_index = nodes.index(u)\n",
    "        v_index = nodes.index(v)\n",
    "        adjacency_matrix[u_index, v_index] = 1\n",
    "    return adjacency_matrix\n",
    "\n",
    "def create_incidence_matrix(graph):\n",
    "    \"\"\"Creates an incidence matrix for a given graph.\"\"\"\n",
    "    nodes = sorted(graph.nodes())\n",
    "    edges = list(graph.edges())  # Get edges as a list of tuples\n",
    "    n = len(nodes)\n",
    "    m = len(edges)\n",
    "\n",
    "    incidence_matrix = np.zeros((n, m), dtype=int)\n",
    "    for j, (u, v) in enumerate(edges):\n",
    "        u_index = nodes.index(u)\n",
    "        v_index = nodes.index(v)\n",
    "        incidence_matrix[u_index, j] = 1\n",
    "        incidence_matrix[v_index, j] = -1  # Or 1, depending on your convention\n",
    "    return incidence_matrix\n",
    "\n",
    "\n",
    "# Assuming 'dual_graph' is the graph you want to analyze\n",
    "# (replace with 'network_graph' or any other graph variable if needed)\n",
    "\n",
    "if dual_graph:\n",
    "    adjacency_matrix = create_adjacency_matrix(dual_graph)\n",
    "    incidence_matrix = create_incidence_matrix(dual_graph)\n",
    "\n",
    "    print(\"Adjacency Matrix:\")\n",
    "    print(adjacency_matrix.shape)\n",
    "\n",
    "    print(\"\\nIncidence Matrix:\")\n",
    "    print(incidence_matrix.shape)\n",
    "else:\n",
    "    print(\"Dual graph not available. Please make sure the dual_graph is created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aee2d4-d383-4dba-8ed3-6b96e7f07199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates TAZ file given network file\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def create_taz_file(edge_list, output_file=\"taz.xml\"):\n",
    "    \"\"\"\n",
    "    Creates a TAZ file with each edge as a TAZ.\n",
    "    \"\"\"\n",
    "    root = ET.Element(\"tazs\")\n",
    "    root.set(\"xmlns:xsi\", \"http://www.w3.org/2001/XMLSchema-instance\")\n",
    "    root.set(\"xsi:noNamespaceSchemaLocation\", \"http://sumo.dlr.de/xsd/taz_file.xsd\")\n",
    "\n",
    "    for i, edge_id in enumerate(edge_list):\n",
    "      taz = ET.SubElement(root, \"taz\")\n",
    "      taz.set(\"id\", str(i+1))  # Assign TAZ IDs starting from 1\n",
    "      taz.set(\"edges\", edge_id)  # Use edge ID as TAZ shape\n",
    "      # Add more attributes if needed, for example:\n",
    "      # taz.set(\"x\", \"0\")\n",
    "      # taz.set(\"y\", \"0\")\n",
    "\n",
    "\n",
    "    tree = ET.ElementTree(root)\n",
    "    ET.indent(tree, space=\"\\t\", level=0) # Add indentation\n",
    "    tree.write(output_file, encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "# Example usage: (Assuming edge_list from previous code)\n",
    "if edge_list:\n",
    "  create_taz_file(edge_list)\n",
    "  print(f\"TAZ file 'taz.xml' created successfully.\")\n",
    "else:\n",
    "  print(f\"Failed to create TAZ file because edge list is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daac9ad-4ba6-44da-8426-a9d134ecd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates Trips file from TAZ files\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "!pip install sumolib\n",
    "import sumolib\n",
    "\n",
    "net  = sumolib.net.readNet(network_file)\n",
    "t=[] #place holder for no. of trips and time steps \n",
    "\n",
    "def generate_random_trips(taz_file, n, output_file=\"trips\"):\n",
    "    \"\"\"Generates a random trips file with a specified number of trips.\"\"\"\n",
    "    new_trips = num_trips + int(random.uniform(-num_trips/2,num_trips/2)) #no. of trips is uniformly distributed with mean as num_trips and deviation of num_trips/2\n",
    "    new_time = time_step + random.uniform(-time_step/2,time_step/2) #time_step is uniformly distributed with mean as time_step and deviation of time_step/2\n",
    "    t.append([new_trips,new_time])\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(taz_file)\n",
    "        root = tree.getroot()\n",
    "        taz_ids = [[taz.get('id') , taz.get('edges')] for taz in root.findall('taz')]\n",
    "\n",
    "        if not taz_ids:\n",
    "            print(f\"Error: No TAZs found in {taz_file}\")\n",
    "            return\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: TAZ file not found at {taz_file}\")\n",
    "        return\n",
    "    except ET.ParseError:\n",
    "        print(f\"Error: Invalid XML format in {taz_file}\")\n",
    "        return\n",
    "\n",
    "    trips_root = ET.Element(\"routes\")\n",
    "    trips_root.set(\"xmlns:xsi\", \"http://www.w3.org/2001/XMLSchema-instance\")\n",
    "    trips_root.set(\"xsi:noNamespaceSchemaLocation\", \"http://sumo.dlr.de/xsd/routes_file.xsd\")\n",
    "\n",
    "    for i in range(new_trips):\n",
    "        # Choose random origin and destination TAZs\n",
    "        origin = random.choice(taz_ids)\n",
    "        destination = random.choice(taz_ids)\n",
    "\n",
    "        shortestpath = net.getShortestPath(net.getEdge(origin[1]),net.getEdge(destination[1]))\n",
    "\n",
    "        while shortestpath[0] is None or origin == destination:\n",
    "            origin = random.choice(taz_ids)\n",
    "            destination = random.choice(taz_ids)\n",
    "\n",
    "            shortestpath = net.getShortestPath(net.getEdge(origin[1]),net.getEdge(destination[1]))\n",
    "\n",
    "        # Ensure origin and destination are different and there is a valid route\n",
    "\n",
    "        trip = ET.SubElement(trips_root, \"trip\")\n",
    "        trip.set(\"id\", f\"{i+1}\")\n",
    "        trip.set(\"depart\", str(i*new_time))  # Uniformly spaced departure times\n",
    "        trip.set(\"from\", origin[1])\n",
    "        trip.set(\"to\", destination[1])\n",
    "\n",
    "        trip.set(\"fromTaz\", origin[0])\n",
    "        trip.set(\"toTaz\", destination[0])\n",
    "        trip.set(\"departLane\", \"free\")\n",
    "        trip.set(\"departSpeed\", \"max\")\n",
    "\n",
    "\n",
    "    tree = ET.ElementTree(trips_root)\n",
    "    ET.indent(tree, space=\"\\t\", level=0)\n",
    "    out = output_file+str(n)+\".xml\"\n",
    "    tree.write(out, encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "    #print(f\"Random trips file {out} created successfully.\")\n",
    "\n",
    "\n",
    "#iterative generation of trips file\n",
    "\n",
    "for j in range(1,datasize):\n",
    "   generate_random_trips(\"taz.xml\", j)  # Pass the TAZ file path\n",
    "   print(f\"done!{j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b7eaa-d536-4b79-ac99-cea32639242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture input features : in_flux,out_flux and total_flux\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def analyze_trips(trips_file, edge_list):\n",
    "    \"\"\"\n",
    "    Analyzes a SUMO trips file and calculates edge coefficients.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(trips_file)\n",
    "        root = tree.getroot()\n",
    "        trips = root.findall('trip')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Trips file not found at {trips_file}\")\n",
    "        return None\n",
    "    except ET.ParseError:\n",
    "        print(f\"Error: Invalid XML format in {trips_file}\")\n",
    "        return None\n",
    "\n",
    "    edge_outflux = {edge+str(\"out\"): 0 for edge in edge_list}\n",
    "    edge_influx = {edge+str(\"in\"): 0 for edge in edge_list}\n",
    "\n",
    "    for trip in trips:\n",
    "        from_edge = trip.get('from')\n",
    "        to_edge = trip.get('to')\n",
    "\n",
    "        if from_edge in edge_list:\n",
    "            edge_outflux[from_edge+str(\"out\")] += 1\n",
    "        if to_edge in edge_list:\n",
    "            edge_influx[to_edge+str(\"in\")] -= 1\n",
    "    edge_coefficients = {**edge_outflux,**edge_influx}\n",
    "\n",
    "    return edge_coefficients\n",
    "    \n",
    "\n",
    "\n",
    "# Example usage:\n",
    "edge_coefficients =[]\n",
    "x = [] #total flux\n",
    "z_in =[] #in flux\n",
    "z_out = [] #out flux\n",
    "for i in range(1,datasize):\n",
    "  trips_files = \"trips\"+str(i)+\".xml\"\n",
    "  edge_coefficients.append(analyze_trips(trips_files, edge_list))\n",
    "  z_in.append([analyze_trips(trips_files,edge_list)[edge+str(\"in\")] for edge in edge_list])\n",
    "  z_out.append([analyze_trips(trips_files,edge_list)[edge+str(\"out\")] for edge in edge_list])  \n",
    "  x.append([analyze_trips(trips_files,edge_list)[edge+str(\"out\")] for edge in edge_list]+[analyze_trips(trips_files,edge_list)[edge+str(\"in\")] for edge in edge_list])\n",
    "  print(f\"done!{i}\")\n",
    "\n",
    "# Create a DataFrame from the edge coefficients\n",
    "df = []\n",
    "dfs = []\n",
    "x = torch.tensor(x,dtype = torch.float)\n",
    "z_in = torch.tensor(z_in,dtype = torch.float)\n",
    "z_out = torch.tensor(z_out,dtype = torch.float)\n",
    "print(x.shape)\n",
    "\n",
    "for i in range(len(edge_coefficients)):\n",
    "  df.append(pd.DataFrame(list(edge_coefficients[i].items()), columns=['Edge', 'Coefficient']))\n",
    "\n",
    "# Display the DataFrame\n",
    "# for i in range(99):\n",
    "#    print(f\"DataFrame {i+1}:\")\n",
    "#    print(df[i])\n",
    "\n",
    "# print(edge_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46590f-e972-496d-b401-1272a8e58c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the simulation in SuMO\n",
    "\n",
    "taz_file = \"taz.xml\"\n",
    "add_file = \"addons.add.xml\"\n",
    "config_file = \"sumo.sumocfg\"\n",
    "routes_file = \"routes\"\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def generate_random_simulations(j):\n",
    "    trip_file = \"trips\"+str(j)+\".xml\"\n",
    "    routes_file = \"routes_WARB\"+str(j)+\".xml\"\n",
    "    config_file = \"sumo\"+str(j)+\".sumocfg\"\n",
    "\n",
    "    with open(config_file, 'w') as f:\n",
    "        f.write('<configuration>\\n')\n",
    "        f.write('    <input>\\n')\n",
    "        f.write(f'        <net-file value=\"{network_file}\"/>\\n')\n",
    "        f.write(f'        <route-files value=\"{trip_file}\"/>\\n')\n",
    "        f.write(f'        <additional-files value=\"{add_file},{taz_file}\"/>\\n')\n",
    "        f.write('    </input>\\n')\n",
    "        f.write('    <output>\\n')\n",
    "        f.write(f'        <vehroute-output value=\"{routes_file}\"/>\\n')\n",
    "        f.write(f'        <vehroute-output.route-length value=\"true\"/>\\n')\n",
    "        f.write(f'        <vehroute-output.last-route value=\"true\"/>\\n')\n",
    "        f.write(f'        <vehroute-output.write-unfinished value=\"true\"/>\\n')\n",
    "        f.write(f'        <vehroute-output.exit-times value=\"true\"/>\\n')\n",
    "        f.write(f'        <vehroute-output.skip-ptlines value=\"true\"/>\\n')\n",
    "        f.write('    </output>\\n')\n",
    "    \n",
    "        # Time configuration\n",
    "        f.write('    <time>\\n')\n",
    "        f.write('        <begin value = \"0\"/>')\n",
    "        f.write('        <step-length value=\"1\" />\\n')\n",
    "        f.write('    </time>\\n')\n",
    "\n",
    "        # Routing parameters\n",
    "        f.write('    <routing>\\n')\n",
    "        f.write('        <routing-algorithm value=\"astar\" />\\n')\n",
    "        f.write('        <weights.random-factor value=\"1.8\" />\\n')\n",
    "        f.write('        <weights.priority-factor value=\"0.5\" />\\n')\n",
    "        f.write('        <device.rerouting.probability value=\"1\" />\\n')\n",
    "        f.write('        <device.rerouting.period value=\"180\" />\\n')\n",
    "        f.write('        <device.rerouting.pre-period value=\"0\" />\\n')\n",
    "        f.write('        <device.rerouting.adaptation-steps value=\"5\" />\\n')\n",
    "        f.write('        <device.rerouting.adaptation-interval value=\"180\" />\\n')\n",
    "        f.write('        <device.rerouting.with-taz value=\"true\" />\\n')\n",
    "        f.write('        <device.rerouting.threads value=\"5\" />\\n')\n",
    "        f.write('        <device.rerouting.synchronize value=\"true\" />\\n')\n",
    "        f.write('    </routing>\\n')\n",
    "    \n",
    "        # Report settings\n",
    "        f.write('    <report>\\n')\n",
    "        f.write('        <verbose value=\"true\" />\\n')\n",
    "        f.write('        <xml-validation value=\"never\" />\\n')\n",
    "        f.write('        <no-warnings value=\"true\" />\\n')\n",
    "        f.write('        <error-log value=\"log.log\" />\\n')\n",
    "        f.write('    </report>\\n')\n",
    "    \n",
    "        # Mesoscopic simulation parameters\n",
    "        f.write('    <mesoscopic>\\n')\n",
    "        f.write('        <mesosim value=\"true\" />\\n')\n",
    "        f.write('        <meso-edgelength value=\"100\" />\\n')\n",
    "        f.write('        <meso-tauff value=\"1.0\" />\\n')\n",
    "        f.write('        <meso-taufj value=\"1.0\" />\\n')\n",
    "        f.write('        <meso-taujf value=\"1.0\" />\\n')\n",
    "        f.write('        <meso-taujj value=\"1.0\" />\\n')\n",
    "        f.write('        <meso-jam-threshold value=\"-0.8\" />\\n')\n",
    "        f.write('        <meso-multi-queue value=\"true\" />\\n')\n",
    "        f.write('        <meso-junction-control value=\"true\" />\\n')\n",
    "        f.write('        <meso-tls-penalty value=\"0\" />\\n')\n",
    "        f.write('        <meso-tls-flow-penalty value=\"0\" />\\n')\n",
    "        f.write('        <meso-minor-penalty value=\"0\" />\\n')\n",
    "        f.write('        <meso-overtaking value=\"true\" />\\n')\n",
    "        f.write('        <meso-lane-queue value=\"true\" />\\n')\n",
    "        f.write('    </mesoscopic>\\n')\n",
    "    \n",
    "        # Random number seed\n",
    "        f.write('    <random_number>\\n')\n",
    "        f.write('        <seed value=\"17\" />\\n')\n",
    "        f.write('    </random_number>\\n')\n",
    "    \n",
    "        # GUI-specific settings (optional)\n",
    "        f.write('    <gui_only>\\n')\n",
    "        f.write('        <tracker-interval value=\"2\" />\\n')\n",
    "        f.write('    </gui_only>\\n')\n",
    "    \n",
    "        # Close the configuration tag\n",
    "        f.write('</configuration>\\n')\n",
    "\n",
    "    #print(f\"SUMO configuration file '{config_file}' created successfully.\")\n",
    "    result = subprocess.run([\"sumo\", \"-c\", config_file], timeout=50)\n",
    "\n",
    "    #print(f\"SUMO simulation ran perfectly\")\n",
    "\n",
    "    \n",
    "# Example usage:\n",
    "for j in range(1,datasize):\n",
    "  generate_random_simulations(j)  # Pass the TAZ file path\n",
    "  print(f\"done!{j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab0709-9bbc-4989-a36c-1a399ef7ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts edge_flows from routes file of the above generated SuMO simulation.\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def count_edge_usage(routes_file, network_file):\n",
    "    \"\"\"\n",
    "    Reads a routes file and network file, counts edge usage, and creates a table.\n",
    "\n",
    "    Args:\n",
    "        routes_file: Path to the routes file (XML).\n",
    "        network_file: Path to the network file (NET.XML).\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with edge IDs as columns and counts as values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        routes_tree = ET.parse(routes_file)\n",
    "        routes_root = routes_tree.getroot()\n",
    "\n",
    "        edge_ids = get_edge_ids(network_file)  # Assuming get_edge_ids is defined as in your previous code\n",
    "        if not edge_ids:\n",
    "            return None\n",
    "\n",
    "        edge_counts = {edge_id: 0 for edge_id in edge_ids}\n",
    "\n",
    "        for route in routes_root.findall('.//route'):\n",
    "            edges = route.get('edges').split()\n",
    "            for edge in edges:\n",
    "                if edge in edge_counts:\n",
    "                    edge_counts[edge] += 1\n",
    "\n",
    "        #print(edge_counts)\n",
    "\n",
    "        return edge_counts\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found.\")\n",
    "        return None\n",
    "    except ET.ParseError:\n",
    "        print(f\"Error: Invalid XML format.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "y = []\n",
    "routesdf = []\n",
    "routes = []\n",
    "for i in range(1,datasize):\n",
    "    routes_file = \"routes_WARB\"+str(i)+\".xml\"  # Replace with your actual routes file path\n",
    "    edge_usage = count_edge_usage(routes_file, network_file)\n",
    "    y.append([edge_usage[edge] for edge in edge_list ])\n",
    "    df = pd.DataFrame(list(edge_usage.items()), columns=['Edge', 'Count'])\n",
    "    # dft = torch.tensor(df, dtype =torch.float)\n",
    "    # print(dft)\n",
    "    # y.append(dft)\n",
    "    routesdf.append(df)\n",
    "    routes.append(edge_usage)\n",
    "    print(f\"done!{i}\")\n",
    "\n",
    "y = torch.tensor(y, dtype=torch.float)\n",
    "print(y.shape)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# for i in range(len(routes)):\n",
    "#    print(f\"DataFrame {i+1}:\")\n",
    "#    print(routesdf[i])\n",
    "# print(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbc6ab-2ed0-47d1-b7c3-d89fd79a4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates dataset for training GNN\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "!pip install torch_geometric\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "def create_gnn_dataset(size):\n",
    "    \n",
    "    dataset = []\n",
    "    for i in range(size):\n",
    "        # Convert adjacency matrix to edge index\n",
    "        edge_index = torch.tensor(np.nonzero(adjacency_matrix), dtype=torch.long)\n",
    "        # Node_Features\n",
    "        node_features = []\n",
    "        for edges in edge_list:\n",
    "              \n",
    "            node_features.append([edge_coefficients[i][edges+str(\"in\")]+edge_coefficients[i][edges+str(\"out\")]])\n",
    "\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "        # Edge features (start and end destination)\n",
    "        edge_attr = torch.zeros(len(incidence_matrix[0]))\n",
    "\n",
    "\n",
    "\n",
    "        # Target variable (edge probabilities)\n",
    "        # Mapping edge IDs to probabilities.  Need to handle potential missing keys.\n",
    "        node_output = []\n",
    "        for edges in edge_list:\n",
    "            node_output.append([routes[i][edges]])\n",
    "\n",
    "        y = torch.tensor(node_output, dtype=torch.float)\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr,y=y)\n",
    "        dataset.append(data)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Create the GNN dataset\n",
    "gnn_dataset = create_gnn_dataset(datasize-1)\n",
    "\n",
    "\n",
    "print(gnn_dataset[9].edge_index.shape)\n",
    "print(gnn_dataset[9].edge_attr.shape)\n",
    "print(gnn_dataset[9].x.shape)\n",
    "print(gnn_dataset[9].y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc30490-0ac8-430f-b889-34c73a304428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3ce9b-0a94-45da-be9a-1eddf7ff19fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
